{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classe Stump\n",
    "\n",
    "- Um Stump, ou Decision Stump, é um modelo de classificação fraco que consiste em ser basicamente uma Árvore de Decisão contendo apenas altura igual à 1 e 2 folhas. Com isso, conseguimos deduzir de onde veio esse nome, visto que Stump é uma tradução literal de tronco de árvore.<br><br>\n",
    "\n",
    "- Modelei um Stump como uma classe para facilitar o uso do mesmo ao longo do algoritmo do AdaBoost. Nela, teremos 3 parâmetros onde 2 podem ser opcionais:\n",
    "    - feature: representa sobre qual feature estaremos aplicando o Stump.\n",
    "    - value: representa o valor daquela feature. No caso do dataset poderá ser x, o ou b.\n",
    "    - pred: representa qual predição será dada caso o valor da feature seja value.<br><br>\n",
    "    \n",
    "- Por exemplo, ao instanciarmos um Stump(0, x, 1) todos os valores iguais à x da feature 0 serão classificados como da classe 1 e classificados como a classe -1 caso contrário.<br><br>\n",
    "\n",
    "- Além das features podemos passar TRUE e FALSE, como strings, para um Stump. Nesse caso, as predições serão sempre 1 caso o Stump seja inicializado com TRUE e -1 caso seja inicializado com FALSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stump:\n",
    "    \"\"\"\n",
    "        Implementation of Stump Model - weak classifier\n",
    "        A Stump is a decision tree with 1 node and 2 leafs only\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, feature, value=None, pred=None):\n",
    "        \"\"\"\n",
    "            Constructor of class\n",
    "            Needs a feature, value and prediction associated with that feature\n",
    "            \n",
    "            Feature can also be TRUE or FALSE, in that case value=None and pred=None by default\n",
    "        \"\"\"\n",
    "        self._pred = pred\n",
    "        self._value = value\n",
    "        self._feature = feature\n",
    "        \n",
    "        \n",
    "    def __str__(self):\n",
    "        \"\"\"\n",
    "            For printing a Stump\n",
    "        \"\"\"\n",
    "        return \"(%s, %s, %s)\" % (self._feature, self._value, self._pred)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "            Class prediction by model (feature, value, pred)\n",
    "            Returns a numpy.ndarray with values -pred and pred\n",
    "        \"\"\"\n",
    "        n_samples = X.shape[0]\n",
    "        \n",
    "        if self._feature == \"TRUE\": # all classes are 1\n",
    "            return np.ones(n_samples).astype(int)\n",
    "        \n",
    "        if self._feature == \"FALSE\": # all classes are -1\n",
    "            return (-1) * np.ones(n_samples).astype(int)\n",
    "        \n",
    "        preds = np.empty(n_samples).astype(int)\n",
    "        for i in range(n_samples):\n",
    "            if X[i, self._feature] == self._value:\n",
    "                preds[i] = self._pred\n",
    "            else:\n",
    "                preds[i] = (-1) * self._pred\n",
    "                \n",
    "        return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classe AdaBoost\n",
    "- AdaBoost é um modelo de aprendizagem de máquina da família ``ensemble``. Ele se baseia na técnica de Boosting utilizando Stumps como classificadores mais fracos. Através destes, o Boosting tenta minimizar o alto viés associado a cada modelo dando a resposta como uma combinação das respostas destes classificadores mais fracos. No caso, cada classificador carregará consigo um peso, indicando o quão influente ele será na resposta final. Seja $H(X)$ a predição do modelo forte, $\\alpha_i$ os pesos e $h_i(X)$ a predição dos classificadores fracos, teremos que:\n",
    "\n",
    "$$ H(X) = sign(\\sum_i^n \\alpha_i * h_i(X)) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaBoost:\n",
    "    \"\"\"\n",
    "        Implementation of AdaBoost ensemble model\n",
    "        It uses Stump classes as weak classifiers\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, stumps_table, debug=False):\n",
    "        \"\"\"\n",
    "            Constructor of class\n",
    "            Needs a premade Stumps Table to be used by the model\n",
    "        \"\"\" \n",
    "        self._alphas  = None\n",
    "        self._weights = None\n",
    "        self._stumps  = None\n",
    "        self._stumps_table = stumps_table\n",
    "        \n",
    "    def _pick_best_stump(self, X, y):\n",
    "        \"\"\"\n",
    "            This function picks the Stump in the Stumps Table that best\n",
    "            minimizes the error given sample weights.\n",
    "\n",
    "            Returns the best Stump model, it's error and predictions\n",
    "        \"\"\"    \n",
    "        best_error = np.inf\n",
    "        best_model = None\n",
    "        best_preds = None\n",
    "\n",
    "        for stump in self._stumps_table:\n",
    "            preds = stump.predict(X)\n",
    "            error = self._weights[(preds != y)].sum()\n",
    "\n",
    "            if error < best_error:\n",
    "                best_model = stump\n",
    "                best_error  = error\n",
    "                best_preds = preds\n",
    "                \n",
    "        return best_model, best_error, best_preds\n",
    "    \n",
    "    def print_stumps(self):\n",
    "        \"\"\"\n",
    "            Only a debug method to print Stumps chose by model\n",
    "            with it's alpha values\n",
    "        \"\"\"\n",
    "        n_stumps = len(self._stumps)\n",
    "        for i in range(n_stumps):\n",
    "            print(\"- Weak classifier %d:\" % (i+1))\n",
    "            print(\"  - Alpha = %.5f\" % self._alphas[i])\n",
    "            print(\"  - Stump =\", self._stumps[i])\n",
    "            print()\n",
    "        \n",
    "    def fit(self, X, y, n_iter):\n",
    "        \"\"\"\n",
    "            Fits model to data\n",
    "            y values must be either 1 or -1\n",
    "            n_iter defines how many iterations the algorithm will execute\n",
    "        \"\"\"\n",
    "        if set(y) != {-1, 1}:\n",
    "            raise ValueError(\"y values must be either 1 or -1\")\n",
    "            \n",
    "        if n_iter <= 0:\n",
    "            raise ValueError(\"The number of iterations must be greater than 0\")\n",
    "            \n",
    "        n_samples = X.shape[0]\n",
    "        self._stumps  = np.empty(n_iter, dtype=Stump)\n",
    "        self._alphas  = np.empty(n_iter)\n",
    "        self._weights = np.ones(n_samples) / n_samples # in the beginning all weights are 1/n\n",
    "        \n",
    "        for i in range(n_iter):\n",
    "            stump, error, preds = self._pick_best_stump(X, y)\n",
    "            \n",
    "            # Computing alpha value for that Stump \n",
    "            alpha = 0.5 * np.log((1 - error) / error)\n",
    "            \n",
    "            # Computing next weights and normalizing\n",
    "            weights = self._weights * np.exp(-alpha * preds * y)\n",
    "            weights /= weights.sum()\n",
    "            \n",
    "            # Saving current iteration values\n",
    "            self._stumps[i] = stump\n",
    "            self._alphas[i] = alpha\n",
    "            self._weights = weights\n",
    "            \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "            Class prediction by model given by dot(alphas, stumps prediction)\n",
    "            Returns a numpy.ndarray with values -1 and 1\n",
    "        \"\"\"\n",
    "        preds = np.array([stump.predict(X) for stump in self._stumps])\n",
    "        return np.sign(np.dot(self._alphas, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Corretude\" usando dados do slide\n",
    "- Usaremos o dataset do \"Vampire\" utilizado em sala de aula para corrigir o modelo implementado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vampire</th>\n",
       "      <th>Evil</th>\n",
       "      <th>Transforms</th>\n",
       "      <th>Sparkly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Vampire Evil Transforms Sparkly\n",
       "0       Y    N          Y       Y\n",
       "1       Y    Y          Y       Y\n",
       "2       Y    Y          N       N\n",
       "3       Y    Y          N       Y\n",
       "4       Y    Y          N       Y\n",
       "5       Y    N          Y       Y\n",
       "6       Y    N          Y       Y\n",
       "7       N    N          Y       N\n",
       "8       N    Y          N       N\n",
       "9       N    N          N       Y"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"Vampire\":    ['Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'N', 'N', 'N'],\n",
    "    \"Evil\":       ['N', 'Y', 'Y', 'Y', 'Y', 'N', 'N', 'N', 'Y', 'N'],\n",
    "    \"Transforms\": ['Y', 'Y', 'N', 'N', 'N', 'Y', 'Y', 'Y', 'N', 'N'],\n",
    "    \"Sparkly\":    ['Y', 'Y', 'N', 'Y', 'Y', 'Y', 'Y', 'N', 'N', 'Y']\n",
    "})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Weak classifier 1:\n",
      "  - Alpha = 0.69315\n",
      "  - Stump = (2, N, -1)\n",
      "\n",
      "- Weak classifier 2:\n",
      "  - Alpha = 0.54931\n",
      "  - Stump = (0, N, -1)\n",
      "\n",
      "- Weak classifier 3:\n",
      "  - Alpha = 0.44365\n",
      "  - Stump = (1, N, -1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(\"Vampire\", axis=1).values\n",
    "y = df[\"Vampire\"].replace(['N', 'Y'], [-1, 1]).values\n",
    "\n",
    "stumps_table = []\n",
    "for feature in range(X.shape[1]):\n",
    "    for value in ['N', 'Y']:\n",
    "        for pred in [-1, 1]:\n",
    "            stumps_table.append(Stump(feature, value, pred))\n",
    "            \n",
    "stumps_table.append(Stump(\"TRUE\"))\n",
    "stumps_table.append(Stump(\"FALSE\"))\n",
    "\n",
    "clf = AdaBoost(stumps_table)\n",
    "clf.fit(X, y, n_iter=3)\n",
    "clf.print_stumps()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Temos que os valores de alpha foram computados de forma correta, porém escolhemos outros Stumps que resultaram na mesma resposta."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
