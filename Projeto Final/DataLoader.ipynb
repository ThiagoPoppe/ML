{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto Final - Aprendizagem de Máquina\n",
    "- Thiago Martin Poppe\n",
    "- Matrícula: 2017014324\n",
    "\n",
    "# Introdução ao dataset\n",
    "- Para esse projeto, escolhi utilizar o dataset ``Traditional Food around the world`` presente no site [Kaggle](https://www.kaggle.com/abhijeetbhilare/world-cuisines). O dataset é formado por diversas imagens que demonstram pratos culinários tradicionais de diversas regiões do mundo, como por exemplo ``American``, ``European`` e ``Indian``.\n",
    "\n",
    "# Objetivo e ideias\n",
    "- O objetivo desse projeto é dado um prato determinar o país de origem do mesmo. Além dessa classificação, usaremos explicabilidade para tentar entender o motivo do modelo ter aprendido que um prato X pertence à região Y. Também iremos comparar diversas arquiteturas propostas para resolver o problema, como por exemplo MLP's, LeNet-5, entre outras.<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # filtering depricated warnings\n",
    "np.random.seed(42) # fixing random seed to 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definições de constantes\n",
    "\n",
    "- Nessa célula definimos \"constantes\" que utilizaremos ao longo do notebook, como por exemplo: diretório raiz que contém as pastas com as imagens, as classes que usaremos, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = \"Dishes/\"\n",
    "IMG_SIZE = 128\n",
    "\n",
    "N_CLASSES = 6\n",
    "CLASSES = {\n",
    "    \"American\": 0, \"Chinese\": 1,\n",
    "    \"European\": 2, \"Indian\":  3,\n",
    "    \"Japanese\": 4, \"Korean\":  5\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções de leitura e exibição de imagens\n",
    "\n",
    "- A função de leitura utiliza a biblioteca ``OpenCv`` para ler, escalar e converter o mapeamento de cores para RGB, visto que, originalmente, a biblioteca lê a imagem com o mapeamento BGR (blue, green, red). Além disso, a função normaliza os valores dos pixels dividindo os mesmos por 255, que corresponde ao valor máximo de um pixel.<br><br>\n",
    "\n",
    "- A função de exibição utiliza a biblioteca ``MatplotLib`` para exibir as imagens. Aqui não temos nada muito complexo, sendo apenas uma chamada de função já implementada na própria biblioteca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(filename):\n",
    "    \"\"\"\n",
    "        Helper function to read an image\n",
    "        \n",
    "        - Parameters:\n",
    "            filename : string\n",
    "        - Return:\n",
    "            A RGB image\n",
    "    \"\"\"\n",
    "    \n",
    "    img = cv2.imread(filename)\n",
    "    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_AREA)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # by default opencv uses BGR\n",
    "    \n",
    "    return np.array(img) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(img, cmap=None):\n",
    "    \"\"\"\n",
    "        Helper function to plot/show image\n",
    "        \n",
    "        - Parameters:\n",
    "            img : Image\n",
    "            cmap : Grayscale, RGB, etc\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.imshow(img, cmap=cmap)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representação one-hot vector\n",
    "- A representação one-hot consiste em termos um vetor composto por 0's e apenas uma posição com valor 1. Utilizamos esse artifício para representar cada classe do nosso dataset.<br><br>\n",
    "\n",
    "- Em um mundo ideal, queremos que a classificação tenha 100% de certeza, i.e que a resposta do classificador seja um vetor contendo apenas um valor 1 e os demais 0. Porém, na prática, isso não irá ocorrer sempre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(label):\n",
    "    \"\"\"\n",
    "        Helper function that creates an one-hot vector given label\n",
    "        \n",
    "        - Parameters:\n",
    "            label: string\n",
    "            \n",
    "        - Return:\n",
    "            An one-hot vector\n",
    "    \"\"\"\n",
    "    \n",
    "    return np.eye(N_CLASSES)[CLASSES[label]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class American will be seen as [1. 0. 0. 0. 0. 0.]\n",
      "Class Chinese will be seen as [0. 1. 0. 0. 0. 0.]\n",
      "Class European will be seen as [0. 0. 1. 0. 0. 0.]\n",
      "Class Indian will be seen as [0. 0. 0. 1. 0. 0.]\n",
      "Class Japanese will be seen as [0. 0. 0. 0. 1. 0.]\n",
      "Class Korean will be seen as [0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "for label in CLASSES:\n",
    "    print(f\"Class {label} will be seen as {one_hot(label)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leitura dos dados\n",
    "- Nessa célula realizamos a leitura dos dados. Cada classe possui sua própria pasta contendo as imagens relacionadas com a comida tradicional da região.<br><br>\n",
    "\n",
    "- Após a leitura e armazenamento de todos os dados em um DataFrame do ``pandas`` nós realizamos um shuffle para não termos futuros problemas com o aprendizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading American dishes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1815/1815 [00:06<00:00, 285.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Chinese dishes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 3030/3030 [00:10<00:00, 292.34it/s]\n",
      "  0%|                                                                                         | 0/1994 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading European dishes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1994/1994 [00:06<00:00, 286.82it/s]\n",
      "  0%|                                                                                         | 0/2453 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Indian dishes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2453/2453 [00:08<00:00, 291.31it/s]\n",
      "  0%|                                                                                         | 0/2065 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Japanese dishes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2065/2065 [00:07<00:00, 280.89it/s]\n",
      "  0%|                                                                                         | 0/2422 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Korean dishes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2422/2422 [00:08<00:00, 276.70it/s]\n"
     ]
    }
   ],
   "source": [
    "imgs = []\n",
    "labels = []\n",
    "counter = {label:0 for label in CLASSES}\n",
    "    \n",
    "for label in CLASSES:\n",
    "    print(f\"Loading {label} dishes...\")        \n",
    "    path = os.path.join(ROOT_DIR, label)\n",
    "    for f in tqdm(os.listdir(path)):\n",
    "        filename = os.path.join(path, f)\n",
    "\n",
    "        try: # some images may be corrupted\n",
    "            imgs.append(read_img(filename))\n",
    "            labels.append(label)\n",
    "            data.append([X, y])\n",
    "            counter[label] += 1\n",
    "\n",
    "        except Expection as E:\n",
    "            print(str(E))\n",
    "\n",
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balanceamento de classes\n",
    "\n",
    "- Como podemos ver, temos uma distribuição balanceada das classes. A maior diferença de dados se encontra entre as classes ``American`` e ``Chinese``, onde a segunda possui $\\approx 1,67$ vezes mais imagens que a primeira."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "American class has 1815 images\n",
      "Chinese class has 3030 images\n",
      "European class has 1994 images\n",
      "Indian class has 2453 images\n",
      "Japanese class has 2065 images\n",
      "Korean class has 2422 images\n"
     ]
    }
   ],
   "source": [
    "for label in counter:\n",
    "    print(f\"{label} class has {counter[label]} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separação entre imagens e classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.Tensor([i[0] for i in data]).view(-1, 3, IMG_SIZE, IMG_SIZE)\n",
    "y = torch.Tensor([i[1] for i in data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arquiteturas utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self._input_size  = input_size\n",
    "        self._hidden_size = hidden_size\n",
    "        \n",
    "        # Defining MLP architecture\n",
    "        self._layers = nn.Sequential(\n",
    "            # Input\n",
    "            nn.Linear(self._input_size, self._hidden_size),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # Hidden Layer\n",
    "            nn.Linear(self._hidden_size, N_CLASSES),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
